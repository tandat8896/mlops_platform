name: CI/CD for Model

on:
  push:
    paths:
      - "data/**"   # data changed
      - "data.dvc" # DVC tracking file changed

  workflow_dispatch:

permissions:
  contents: read
  packages: write

env:
  REGISTRY: ghcr.io
  IMAGE_NAME: ${{ github.repository }}

jobs:

  train_on_server:
    name: Train Model on Remote Server
    runs-on: ubuntu-latest

    steps:
    - name: SSH and run training
      uses: appleboy/ssh-action@v1.1.0
      env:
        AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
        AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
      with:
        host: ${{ secrets.EC2_HOST }}
        username: ${{ secrets.EC2_USER }}
        key: ${{ secrets.EC2_KEY }}
        port: ${{ secrets.EC2_PORT_SSH }}
        envs: AWS_ACCESS_KEY_ID,AWS_SECRET_ACCESS_KEY
        script: |
          echo "=== Setting up environment ==="
          cd $HOME/Repository/mlops_platform
          
          echo "=== Pull latest code ==="
          git stash || true
          git pull
          
          echo "=== Check if data.dvc changed ==="
          DATA_CHANGED=$(git diff HEAD~1 HEAD --name-only 2>/dev/null | grep -q "data.dvc" && echo "true" || echo "false")
          echo "Data changed: $DATA_CHANGED"
          
          echo "=== Initialize Conda ==="
          # Try to find and activate conda
          if [ -f "$HOME/miniconda3/bin/activate" ]; then
            source "$HOME/miniconda3/bin/activate"
          elif [ -f "$HOME/miniconda3/etc/profile.d/conda.sh" ]; then
            source "$HOME/miniconda3/etc/profile.d/conda.sh"
          elif [ -f "$HOME/anaconda3/etc/profile.d/conda.sh" ]; then
            source "$HOME/anaconda3/etc/profile.d/conda.sh"
          elif command -v conda &> /dev/null; then
            eval "$(conda shell.bash hook)" 2>/dev/null || true
          else
            echo "Conda not found, using venv..."
            if [ -f ".venv/bin/activate" ]; then
              source .venv/bin/activate
            elif [ -f "$HOME/venv-mlops/bin/activate" ]; then
              source $HOME/venv-mlops/bin/activate
            else
              echo "ERROR: No Python environment found!"
              exit 1
            fi
          fi
          
          # Activate conda environment if conda is available
          if command -v conda &> /dev/null; then
            conda activate mlops-cicd || {
              conda create -n mlops-cicd python=3.11 -y
              conda activate mlops-cicd
            }
          fi
          
          # Install DVC if needed
          if ! command -v dvc &> /dev/null; then
            echo "Installing DVC..."
            pip install --no-cache-dir dvc[s3]
          fi
          
          echo "=== Check system resources ==="
          echo "Memory:"
          free -h
          echo "Disk space:"
          df -h $HOME/Repository/mlops_platform
          
          echo "=== Cleanup before training ==="
          # Kill any stuck processes
          pkill -f "dvc repro" 2>/dev/null || true
          pkill -f "python.*train.py" 2>/dev/null || true
          sleep 2
          
          # Remove DVC lock files
          rm -f .dvc/tmp/rwlock 2>/dev/null || true
          
          # Clean Python cache
          find . -type d -name __pycache__ -exec rm -r {} + 2>/dev/null || true
          find . -type f -name "*.pyc" -delete 2>/dev/null || true
          
          echo "=== Start MLflow Server ==="
          # Check if MLflow server is already running
          if curl -s -f http://localhost:5001/api/2.0/mlflow/experiments/search > /dev/null 2>&1; then
            echo "✓ MLflow server already running"
          else
            echo "Starting MLflow server..."
            # Install MLflow if needed
            if ! python -c "import mlflow" 2>/dev/null; then
              pip install --no-cache-dir mlflow==3.7.0
            fi
            
            # Create MLflow data directory
            mkdir -p mlflow/run_env/data
            cd mlflow/run_env/data
            
            # Start MLflow server in background
            nohup python -m mlflow server \
              --backend-store-uri sqlite:///./mlflow.db \
              --serve-artifacts \
              --host 0.0.0.0 \
              --port 5001 \
              > /tmp/mlflow.log 2>&1 &
            
            echo "Waiting for MLflow server..."
            sleep 5
            for i in {1..10}; do
              if curl -s -f http://localhost:5001/api/2.0/mlflow/experiments/search > /dev/null 2>&1; then
                echo "✓ MLflow server ready"
                break
              fi
              sleep 2
            done
            
            cd $HOME/Repository/mlops_platform
          fi
          
          export MLFLOW_TRACKING_URI="http://localhost:5001"
          echo "MLFLOW_TRACKING_URI=$MLFLOW_TRACKING_URI"
          
          echo "=== Pull latest DVC data ==="
          dvc pull
          
          echo "=== Run DVC pipeline ==="
          if [ "$DATA_CHANGED" = "true" ]; then
            echo "Data changed detected - forcing training"
            dvc repro --force 2>&1 | tee /tmp/dvc_training.log
          else
            echo "No data changes - running regular pipeline"
            dvc repro 2>&1 | tee /tmp/dvc_training.log
          fi
          
          echo "=== Check training result ==="
          if [ ${PIPESTATUS[0]} -ne 0 ]; then
            echo "ERROR: Training failed with exit code ${PIPESTATUS[0]}"
            echo "Last 50 lines of training log:"
            tail -50 /tmp/dvc_training.log
            exit 1
          fi
          
          echo "=== Push artifacts back to DVC remote ==="
          dvc push

  build_and_push:
    name: Build Docker image & Push GHCR
    needs: train_on_server
    runs-on: ubuntu-latest
    permissions:
      contents: read
      packages: write
    outputs:
      image_name: ${{ steps.image.outputs.value }}

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set lowercase image name
      id: image
      run: |
        IMAGE_LOWER=$(echo "${{ github.repository }}" | tr '[:upper:]' '[:lower:]')
        echo "IMAGE_NAME_LOWER=${IMAGE_LOWER}" >> $GITHUB_ENV
        echo "value=${IMAGE_LOWER}" >> $GITHUB_OUTPUT

    - name: Setup Docker Buildx
      uses: docker/setup-buildx-action@v3

    - name: Login to GHCR
      uses: docker/login-action@v3
      with:
        registry: ${{ env.REGISTRY }}
        username: ${{ github.actor }}
        password: ${{ secrets.GITHUB_TOKEN }}

    - name: Generate tag metadata
      id: tag
      run: |
        MODEL_VERSION=$(date +%Y%m%d-%H%M%S)
        TIMESTAMP=$(date +%Y%m%d-%H%M%S)
        echo "model_version=$MODEL_VERSION" >> $GITHUB_OUTPUT
        echo "timestamp=$TIMESTAMP" >> $GITHUB_OUTPUT

    - name: Docker Metadata
      id: meta
      uses: docker/metadata-action@v5
      with:
        images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME_LOWER }}
        tags: |
          type=raw,value=latest
          type=raw,value=model-${{ steps.tag.outputs.model_version }}
          type=raw,value=deploy-${{ steps.tag.outputs.timestamp }}
          type=sha,prefix=sha-

    - name: Build & Push Docker image
      uses: docker/build-push-action@v6
      with:
        context: .
        push: true
        tags: ${{ steps.meta.outputs.tags }}
        labels: ${{ steps.meta.outputs.labels }}
        build-args: |
          MODEL_VERSION=${{ steps.tag.outputs.model_version }}
        cache-from: type=gha
        cache-to: type=gha,mode=max

  deploy_ec2:
    name: Deploy to EC2
    needs: build_and_push
    runs-on: ubuntu-latest

    steps:
    - name: SSH deploy container on EC2
      uses: appleboy/ssh-action@v1.1.0
      env:
        IMAGE_NAME: ${{ needs.build_and_push.outputs.image_name }}
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        GITHUB_ACTOR: ${{ github.actor }}
      with:
        host: ${{ secrets.EC2_HOST }}
        username: ${{ secrets.EC2_USER }}
        key: ${{ secrets.EC2_KEY }}
        port: ${{ secrets.EC2_PORT_DEPLOY }}
        envs: IMAGE_NAME,GITHUB_TOKEN,GITHUB_ACTOR
        script: |
          echo "Logging in to GitHub Container Registry"
          echo ${GITHUB_TOKEN} | docker login ghcr.io -u ${GITHUB_ACTOR} --password-stdin
          
          echo "Pulling latest image"
          docker pull ghcr.io/${IMAGE_NAME}:latest
          
          echo "Stopping and removing old container"
          docker stop app-container || true
          docker rm app-container || true
          
          echo "Starting new container"
          docker run -d --name app-container -p 8000:8000 \
            --restart unless-stopped \
            -e AWS_ACCESS_KEY_ID=${{ secrets.AWS_ACCESS_KEY_ID }} \
            -e AWS_SECRET_ACCESS_KEY=${{ secrets.AWS_SECRET_ACCESS_KEY }} \
            -e S3_BUCKET=${{ secrets.S3_BUCKET }} \
            ghcr.io/${IMAGE_NAME}:latest
          
          echo "Cleaning up old images"
          docker image prune -f
