name: CI/CD for Model

on:
  push:
    paths:
      - "data/**"   # data changed
      - "data.dvc" # DVC tracking file changed

  workflow_dispatch:

env:
  REGISTRY: ghcr.io
  IMAGE_NAME: ${{ github.repository }}

jobs:

  train_on_server:
    name: Train Model on Remote Server
    runs-on: ubuntu-latest

    steps:
    - name: SSH and run training
      uses: appleboy/ssh-action@v1.1.0
      env:
        AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
        AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
      with:
        host: ${{ secrets.EC2_HOST }}
        username: ${{ secrets.EC2_USER }}
        key: ${{ secrets.EC2_KEY }}
        port: ${{ secrets.EC2_PORT_SSH }}
        envs: AWS_ACCESS_KEY_ID,AWS_SECRET_ACCESS_KEY
        script: |
          echo "=== Setting up environment ==="
          cd $HOME/Repository/mlops_platform
          
          echo "=== Pull latest code ==="
          # Stash or reset local changes to allow pull
          git stash || true
          git pull || {
            echo "Git pull failed, trying to reset and pull..."
            git reset --hard origin/master || git reset --hard origin/main || true
            git pull
          }
          
          echo "=== Check if data.dvc changed ==="
          DATA_CHANGED=$(git diff HEAD~1 HEAD --name-only | grep -q "data.dvc" && echo "true" || echo "false")
          echo "Data changed: $DATA_CHANGED"
          
          echo "=== Find and Setup Python Environment ==="
          # Setup PATH first
          export PATH="$HOME/bin:$HOME/.local/bin:/usr/local/bin:/usr/bin:/bin:$PATH"
          
          # Try to find conda in multiple locations
          CONDA_PATHS=(
            "$HOME/miniconda3"
            "$HOME/anaconda3"
            "/opt/conda"
            "/usr/local/miniconda3"
            "/usr/local/anaconda3"
            "/home/ec2-user/miniconda3"
            "/home/ubuntu/miniconda3"
          )
          
          CONDA_FOUND=false
          CONDA_PATH=""
          
          # Search for conda in paths
          for path in "${CONDA_PATHS[@]}"; do
            if [ -f "$path/etc/profile.d/conda.sh" ]; then
              echo "Found conda at: $path"
              CONDA_PATH="$path"
              CONDA_FOUND=true
              break
            fi
          done
          
          # If not found, check .bashrc or .bash_profile
          if [ "$CONDA_FOUND" = false ]; then
            if [ -f "$HOME/.bashrc" ] && grep -q "conda" "$HOME/.bashrc"; then
              echo "Found conda reference in .bashrc, sourcing..."
              source "$HOME/.bashrc" 2>/dev/null || true
              if command -v conda &> /dev/null; then
                CONDA_FOUND=true
                CONDA_PATH=$(conda info --base 2>/dev/null || echo "")
              fi
            fi
          fi
          
          # If still not found, check PATH
          if [ "$CONDA_FOUND" = false ]; then
            if command -v conda &> /dev/null; then
              echo "Conda found in PATH: $(which conda)"
              CONDA_FOUND=true
              CONDA_PATH=$(conda info --base 2>/dev/null || echo "")
            fi
          fi
          
          if [ "$CONDA_FOUND" = true ]; then
            echo "Using Conda environment"
            # Initialize conda
            if [ -n "$CONDA_PATH" ] && [ -f "$CONDA_PATH/etc/profile.d/conda.sh" ]; then
              source "$CONDA_PATH/etc/profile.d/conda.sh"
            elif command -v conda &> /dev/null; then
              eval "$(conda shell.bash hook)" 2>/dev/null || true
            fi
            
            # Activate environment
            if conda env list 2>/dev/null | grep -q "mlops-cicd"; then
              echo "Activating conda environment: mlops-cicd"
              conda activate mlops-cicd
            else
              echo "WARNING: conda environment 'mlops-cicd' not found"
              echo "Available environments:"
              conda env list 2>/dev/null || true
            fi
          else
            echo "Conda not found, trying virtual environment or system Python..."
            # Try virtual environment
            VENV_DIR="$HOME/Repository/mlops_platform/.venv"
            VENV_HOME="$HOME/venv-mlops"
            
            if [ -f "$VENV_DIR/bin/activate" ]; then
              echo "Using virtual environment at: $VENV_DIR"
              source "$VENV_DIR/bin/activate"
            elif [ -f "$VENV_HOME/bin/activate" ]; then
              echo "Using virtual environment at: $VENV_HOME"
              source "$VENV_HOME/bin/activate"
            else
              echo "No virtual environment found, using system Python"
              # Check if Python is available
              if ! command -v python3 &> /dev/null && ! command -v python &> /dev/null; then
                echo "ERROR: Python not found!"
                exit 1
              fi
            fi
          fi
          
          # Verify Python environment
          echo "Python environment: ${CONDA_DEFAULT_ENV:-${VIRTUAL_ENV:-system}}"
          echo "Python: $(which python3 2>/dev/null || which python 2>/dev/null || echo 'not found')"
          echo "Pip: $(which pip3 2>/dev/null || which pip 2>/dev/null || echo 'not found')"
          
          # Check if DVC is installed, if not install it
          if ! command -v dvc &> /dev/null; then
            echo "DVC not found, installing..."
            if [ "$CONDA_FOUND" = true ]; then
              conda install -y -c conda-forge dvc dvc-s3 || pip install --no-cache-dir dvc[s3]
            else
              pip3 install --no-cache-dir dvc[s3] || pip install --no-cache-dir dvc[s3]
            fi
          fi
          
          echo "DVC version: $(dvc --version 2>/dev/null || echo 'not found')"
          
          echo "=== Start MLflow Server ==="
          # Create MLflow data directory
          MLFLOW_DATA_DIR="$HOME/Repository/mlops_platform/mlflow/run_env/data"
          mkdir -p "$MLFLOW_DATA_DIR"
          
          # Try to find Docker in multiple locations
          DOCKER_CMD=""
          DOCKER_PATHS=(
            "/usr/bin/docker"
            "/usr/local/bin/docker"
            "/snap/bin/docker"
            "$HOME/bin/docker"
          )
          
          for path in "${DOCKER_PATHS[@]}"; do
            if [ -f "$path" ] && [ -x "$path" ]; then
              DOCKER_CMD="$path"
              break
            fi
          done
          
          # Also check in PATH
          if [ -z "$DOCKER_CMD" ] && command -v docker &> /dev/null; then
            DOCKER_CMD=$(which docker)
          fi
          
          # Try to start Docker service if not running
          if [ -n "$DOCKER_CMD" ]; then
            if ! $DOCKER_CMD info > /dev/null 2>&1; then
              echo "Docker found but daemon not running, trying to start..."
              sudo systemctl start docker 2>/dev/null || sudo service docker start 2>/dev/null || true
              sleep 3
            fi
          fi
          
          # Try to use Docker if available
          if [ -n "$DOCKER_CMD" ] && $DOCKER_CMD info > /dev/null 2>&1; then
            echo "Using Docker to run MLflow server"
            # Check if MLflow container is already running
            if $DOCKER_CMD ps | grep -q "mlflow_server"; then
              echo "MLflow server container already running"
            else
              echo "Starting MLflow server container..."
              # Stop and remove old container if exists
              $DOCKER_CMD stop mlflow_server 2>/dev/null || true
              $DOCKER_CMD rm mlflow_server 2>/dev/null || true
              
              # Start MLflow server using Docker
              $DOCKER_CMD run -d \
                --name mlflow_server \
                -p 5001:5000 \
                -v "$MLFLOW_DATA_DIR:/mlflow" \
                --restart unless-stopped \
                python:3.11.9-slim \
                bash -c "pip install --no-cache-dir mlflow==3.7.0 && mlflow server --backend-store-uri sqlite:////mlflow/mlflow.db --serve-artifacts --host 0.0.0.0 --port 5000"
              
              # Wait for MLflow server to be ready
              echo "Waiting for MLflow server to start..."
              for i in {1..30}; do
                sleep 2
                if curl -s -f http://localhost:5001/api/2.0/mlflow/experiments/search > /dev/null 2>&1; then
                  echo "✓ MLflow server is ready!"
                  break
                fi
                if [ $i -eq 30 ]; then
                  echo "WARNING: MLflow server may not be ready after 1 minute"
                  $DOCKER_CMD logs mlflow_server --tail 20 || true
                fi
              done
            fi
          else
            echo "Docker not available, starting MLflow server directly with Python..."
            # Check if MLflow is installed
            if ! python3 -c "import mlflow" 2>/dev/null && ! python -c "import mlflow" 2>/dev/null; then
              echo "Installing MLflow..."
              pip3 install --no-cache-dir mlflow==3.7.0 || pip install --no-cache-dir mlflow==3.7.0
            fi
            
            # Check if MLflow server is already running and accessible
            MLFLOW_RUNNING=false
            if pgrep -f "mlflow server" > /dev/null; then
              echo "MLflow server process found, checking if accessible..."
              if curl -s -f http://localhost:5001/api/2.0/mlflow/experiments/search > /dev/null 2>&1; then
                echo "✓ MLflow server is already running and accessible"
                MLFLOW_RUNNING=true
              else
                echo "MLflow process found but not accessible, killing and restarting..."
                pkill -f "mlflow server" || true
                sleep 2
              fi
            fi
            
            if [ "$MLFLOW_RUNNING" = false ]; then
              echo "Starting MLflow server in background..."
              cd "$MLFLOW_DATA_DIR"
              
              # Kill any existing MLflow processes on port 5001
              lsof -ti:5001 | xargs kill -9 2>/dev/null || true
              sleep 1
              
              # Start MLflow server
              nohup python3 -m mlflow server \
                --backend-store-uri sqlite:///./mlflow.db \
                --serve-artifacts \
                --host 0.0.0.0 \
                --port 5001 \
                > /tmp/mlflow.log 2>&1 &
              MLFLOW_PID=$!
              echo "MLflow server started with PID: $MLFLOW_PID"
              
              # Give it a moment to start
              sleep 3
              
              # Wait for MLflow server to be ready
              echo "Waiting for MLflow server to start..."
              for i in {1..30}; do
                sleep 2
                if curl -s -f http://localhost:5001/api/2.0/mlflow/experiments/search > /dev/null 2>&1; then
                  echo "✓ MLflow server is ready!"
                  break
                fi
                if [ $i -eq 30 ]; then
                  echo "WARNING: MLflow server may not be ready after 1 minute"
                  tail -n 20 /tmp/mlflow.log || true
                fi
              done
            fi
          fi
          
          # Set MLflow tracking URI
          export MLFLOW_TRACKING_URI="http://localhost:5001"
          echo "MLFLOW_TRACKING_URI set to: $MLFLOW_TRACKING_URI"
          
          echo "=== Pull latest DVC data ==="
          dvc pull
          
          echo "=== Run DVC pipeline ==="
          if [ "$DATA_CHANGED" = "true" ]; then
            echo "Data changed detected - forcing training"
            dvc repro --force
          else
            echo "No data changes - running regular pipeline"
            dvc repro
          fi
          
          echo "=== Push artifacts back to DVC remote ==="
          dvc push

  build_and_push:
    name: Build Docker image & Push GHCR
    needs: train_on_server
    runs-on: ubuntu-latest
    outputs:
      image_name: ${{ steps.image.outputs.value }}

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set lowercase image name
      id: image
      run: |
        IMAGE_LOWER=$(echo "${{ github.repository }}" | tr '[:upper:]' '[:lower:]')
        echo "IMAGE_NAME_LOWER=${IMAGE_LOWER}" >> $GITHUB_ENV
        echo "value=${IMAGE_LOWER}" >> $GITHUB_OUTPUT

    - name: Setup Docker Buildx
      uses: docker/setup-buildx-action@v3

    - name: Login to GHCR
      uses: docker/login-action@v3
      with:
        registry: ${{ env.REGISTRY }}
        username: ${{ github.actor }}
        password: ${{ secrets.GITHUB_TOKEN }}

    - name: Generate tag metadata
      id: tag
      run: |
        MODEL_VERSION=$(date +%Y%m%d-%H%M%S)
        TIMESTAMP=$(date +%Y%m%d-%H%M%S)
        echo "model_version=$MODEL_VERSION" >> $GITHUB_OUTPUT
        echo "timestamp=$TIMESTAMP" >> $GITHUB_OUTPUT

    - name: Docker Metadata
      id: meta
      uses: docker/metadata-action@v5
      with:
        images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME_LOWER }}
        tags: |
          type=raw,value=latest
          type=raw,value=model-${{ steps.tag.outputs.model_version }}
          type=raw,value=deploy-${{ steps.tag.outputs.timestamp }}
          type=sha,prefix=sha-

    - name: Build & Push Docker image
      uses: docker/build-push-action@v6
      with:
        context: .
        push: true
        tags: ${{ steps.meta.outputs.tags }}
        labels: ${{ steps.meta.outputs.labels }}
        build-args: |
          MODEL_VERSION=${{ steps.tag.outputs.model_version }}
        cache-from: type=gha
        cache-to: type=gha,mode=max

  deploy_ec2:
    name: Deploy to EC2
    needs: build_and_push
    runs-on: ubuntu-latest

    steps:
    - name: SSH deploy container on EC2
      uses: appleboy/ssh-action@v1.1.0
      env:
        IMAGE_NAME: ${{ needs.build_and_push.outputs.image_name }}
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        GITHUB_ACTOR: ${{ github.actor }}
      with:
        host: ${{ secrets.EC2_HOST }}
        username: ${{ secrets.EC2_USER }}
        key: ${{ secrets.EC2_KEY }}
        port: ${{ secrets.EC2_PORT_DEPLOY }}
        envs: IMAGE_NAME,GITHUB_TOKEN,GITHUB_ACTOR
        script: |
          echo "Logging in to GitHub Container Registry"
          echo ${GITHUB_TOKEN} | docker login ghcr.io -u ${GITHUB_ACTOR} --password-stdin
          
          echo "Pulling latest image"
          docker pull ghcr.io/${IMAGE_NAME}:latest
          
          echo "Stopping and removing old container"
          docker stop app-container || true
          docker rm app-container || true
          
          echo "Starting new container"
          docker run -d --name app-container -p 8000:8000 \
            --restart unless-stopped \
            -e AWS_ACCESS_KEY_ID=${{ secrets.AWS_ACCESS_KEY_ID }} \
            -e AWS_SECRET_ACCESS_KEY=${{ secrets.AWS_SECRET_ACCESS_KEY }} \
            -e S3_BUCKET=${{ secrets.S3_BUCKET }} \
            ghcr.io/${IMAGE_NAME}:latest
          
          echo "Cleaning up old images"
          docker image prune -f
