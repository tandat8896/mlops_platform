name: CI/CD for Model

on:
  push:
    paths:
      - "data/**"   # data changed
      - "data.dvc" # DVC tracking file changed

  workflow_dispatch:

permissions:
  contents: read
  packages: write

env:
  REGISTRY: ghcr.io
  IMAGE_NAME: ${{ github.repository }}

jobs:

  train_on_server:
    name: Train Model on Remote Server
    runs-on: ubuntu-latest

    steps:
    - name: SSH and run training
      uses: appleboy/ssh-action@v1.1.0
      env:
        AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
        AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
      with:
        host: ${{ secrets.EC2_HOST }}
        username: ${{ secrets.EC2_USER }}
        key: ${{ secrets.EC2_KEY }}
        port: ${{ secrets.EC2_PORT_SSH }}
        envs: AWS_ACCESS_KEY_ID,AWS_SECRET_ACCESS_KEY
        script: |
          set +e  # Don't exit on error for cleanup commands
          echo "=== Setting up environment ==="
          echo "User: $(whoami)"
          echo "Home: $HOME"
          echo "PWD: $(pwd)"
          
          # Install Git if not found
          if ! command -v git &> /dev/null; then
            echo "Installing Git..."
            sudo apt-get update -qq
            sudo apt-get install -y git
          fi
          
          # Setup repository directory
          REPO_DIR="$HOME/Repository/mlops_platform"
          if [ ! -d "$REPO_DIR" ]; then
            echo "Repository directory not found, creating..."
            mkdir -p "$HOME/Repository"
            cd "$HOME/Repository"
            echo "Cloning repository..."
            git clone https://github.com/tandat8896/mlops_platform.git mlops_platform || {
              echo "ERROR: Failed to clone repository"
              exit 1
            }
          fi
          
          cd "$REPO_DIR"
          echo "Current directory: $(pwd)"
          
          echo "=== Check git remote ==="
          echo "Current remotes:"
          git remote -v
          
          # Ensure origin points to correct repo (don't remove other remotes)
          if git remote get-url origin 2>/dev/null | grep -q "tandat8896/mlops_platform"; then
            echo "✓ Origin remote is correct"
          else
            echo "Setting origin to correct repository..."
            git remote set-url origin https://github.com/tandat8896/mlops_platform.git 2>/dev/null || \
            git remote add origin https://github.com/tandat8896/mlops_platform.git
          fi
          
          echo "=== Pull latest code ==="
          git stash || true
          git fetch origin
          git pull origin master || git pull origin main
          
          echo "=== Check if data.dvc changed ==="
          DATA_CHANGED=$(git diff HEAD~1 HEAD --name-only 2>/dev/null | grep -q "data.dvc" && echo "true" || echo "false")
          echo "Data changed: $DATA_CHANGED"
          
          echo "=== Initialize Conda ==="
          # Try to find and activate conda
          if [ -f "$HOME/miniconda3/bin/activate" ]; then
            source "$HOME/miniconda3/bin/activate"
          elif [ -f "$HOME/miniconda3/etc/profile.d/conda.sh" ]; then
            source "$HOME/miniconda3/etc/profile.d/conda.sh"
          elif [ -f "$HOME/anaconda3/etc/profile.d/conda.sh" ]; then
            source "$HOME/anaconda3/etc/profile.d/conda.sh"
          elif command -v conda &> /dev/null; then
            eval "$(conda shell.bash hook)" 2>/dev/null || true
          else
            echo "Conda not found, using venv..."
            if [ -f ".venv/bin/activate" ]; then
              source .venv/bin/activate
            elif [ -f "$HOME/venv-mlops/bin/activate" ]; then
              source $HOME/venv-mlops/bin/activate
            else
              echo "ERROR: No Python environment found!"
              exit 1
            fi
          fi
          
          # Activate conda environment if conda is available
          if command -v conda &> /dev/null; then
            conda activate mlops-cicd || {
              conda create -n mlops-cicd python=3.11 -y
              conda activate mlops-cicd
            }
          fi
          
          # Install DVC if needed
          if ! command -v dvc &> /dev/null; then
            echo "Installing DVC..."
            # Make sure pip is available
            if ! command -v pip &> /dev/null && ! command -v pip3 &> /dev/null; then
              echo "Installing pip..."
              sudo apt-get install -y python3-pip
            fi
            pip install --no-cache-dir dvc[s3] || pip3 install --no-cache-dir dvc[s3]
          fi
          
          set -e  # Re-enable exit on error
          
          echo "=== Check system resources ==="
          echo "Memory:"
          free -h
          echo "Disk space:"
          df -h $HOME/Repository/mlops_platform
          
          echo "=== Cleanup before training ==="
          # Kill any stuck dvc repro processes (but not current script)
          CURRENT_PID=$$
          for pid in $(ps aux | grep "[d]vc repro" | awk '{print $2}'); do
            if [ "$pid" != "$CURRENT_PID" ]; then
              echo "Killing stuck dvc repro process: $pid"
              kill -9 "$pid" 2>/dev/null || true
            fi
          done
          
          # Wait a bit for processes to die
          sleep 3
          
          # Remove DVC lock files
          rm -f .dvc/tmp/rwlock 2>/dev/null || true
          rm -rf .dvc/tmp/* 2>/dev/null || true
          
          # Clean Python cache
          find . -type d -name __pycache__ -exec rm -r {} + 2>/dev/null || true
          find . -type f -name "*.pyc" -delete 2>/dev/null || true
          
          set -e  # Re-enable exit on error for important commands
          
          echo "=== Start MLflow Server ==="
          # Check if MLflow server is already running
          if curl -s -f http://localhost:5001/api/2.0/mlflow/experiments/search > /dev/null 2>&1; then
            echo "✓ MLflow server already running"
          else
            echo "Starting MLflow server..."
            # Install MLflow if needed
            if ! python -c "import mlflow" 2>/dev/null; then
              pip install --no-cache-dir mlflow==3.7.0
            fi
            
            # Create MLflow data directory
            mkdir -p mlflow/run_env/data
            cd mlflow/run_env/data
            
            # Start MLflow server in background
            nohup python -m mlflow server \
              --backend-store-uri sqlite:///./mlflow.db \
              --serve-artifacts \
              --host 0.0.0.0 \
              --port 5001 \
              > /tmp/mlflow.log 2>&1 &
            
            echo "Waiting for MLflow server..."
            sleep 5
            for i in {1..10}; do
              if curl -s -f http://localhost:5001/api/2.0/mlflow/experiments/search > /dev/null 2>&1; then
                echo "✓ MLflow server ready"
                break
              fi
              sleep 2
            done
            
            cd $HOME/Repository/mlops_platform
          fi
          
          export MLFLOW_TRACKING_URI="http://localhost:5001"
          echo "MLFLOW_TRACKING_URI=$MLFLOW_TRACKING_URI"
          
          echo "=== Pull latest DVC data ==="
          dvc pull
          
          echo "=== Run DVC pipeline ==="
          if [ "$DATA_CHANGED" = "true" ]; then
            echo "Data changed detected - forcing training"
            dvc repro --force 2>&1 | tee /tmp/dvc_training.log
          else
            echo "No data changes - running regular pipeline"
            dvc repro 2>&1 | tee /tmp/dvc_training.log
          fi
          
          echo "=== Check training result ==="
          if [ ${PIPESTATUS[0]} -ne 0 ]; then
            echo "ERROR: Training failed with exit code ${PIPESTATUS[0]}"
            echo "Last 50 lines of training log:"
            tail -50 /tmp/dvc_training.log
            exit 1
          fi
          
          echo "=== Push artifacts back to DVC remote ==="
          dvc push

  build_and_push:
    name: Build Docker image & Push GHCR
    needs: train_on_server
    runs-on: ubuntu-latest
    permissions:
      contents: read
      packages: write
    outputs:
      image_name: ${{ steps.image.outputs.value }}

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set lowercase image name
      id: image
      run: |
        IMAGE_LOWER=$(echo "${{ github.repository }}" | tr '[:upper:]' '[:lower:]')
        echo "IMAGE_NAME_LOWER=${IMAGE_LOWER}" >> $GITHUB_ENV
        echo "value=${IMAGE_LOWER}" >> $GITHUB_OUTPUT

    - name: Setup Docker Buildx
      uses: docker/setup-buildx-action@v3

    - name: Login to GHCR
      uses: docker/login-action@v3
      with:
        registry: ${{ env.REGISTRY }}
        username: ${{ github.actor }}
        password: ${{ secrets.GITHUB_TOKEN }}

    - name: Generate tag metadata
      id: tag
      run: |
        MODEL_VERSION=$(date +%Y%m%d-%H%M%S)
        TIMESTAMP=$(date +%Y%m%d-%H%M%S)
        echo "model_version=$MODEL_VERSION" >> $GITHUB_OUTPUT
        echo "timestamp=$TIMESTAMP" >> $GITHUB_OUTPUT

    - name: Docker Metadata
      id: meta
      uses: docker/metadata-action@v5
      with:
        images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME_LOWER }}
        tags: |
          type=raw,value=latest
          type=raw,value=model-${{ steps.tag.outputs.model_version }}
          type=raw,value=deploy-${{ steps.tag.outputs.timestamp }}
          type=sha,prefix=sha-

    - name: Build & Push Docker image
      uses: docker/build-push-action@v6
      with:
        context: .
        push: true
        tags: ${{ steps.meta.outputs.tags }}
        labels: ${{ steps.meta.outputs.labels }}
        build-args: |
          MODEL_VERSION=${{ steps.tag.outputs.model_version }}
        cache-from: type=gha
        cache-to: type=gha,mode=min

  deploy_ec2:
    name: Deploy to EC2
    needs: build_and_push
    runs-on: ubuntu-latest

    steps:
    - name: SSH deploy container on EC2
      uses: appleboy/ssh-action@v1.1.0
      env:
        IMAGE_NAME: ${{ needs.build_and_push.outputs.image_name }}
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        GITHUB_ACTOR: ${{ github.actor }}
      with:
        host: ${{ secrets.EC2_HOST }}
        username: ${{ secrets.EC2_USER }}
        key: ${{ secrets.EC2_KEY }}
        port: ${{ secrets.EC2_PORT_DEPLOY }}
        envs: IMAGE_NAME,GITHUB_TOKEN,GITHUB_ACTOR
        script: |
          echo "=== Check Docker installation ==="
          # Find docker binary
          if command -v docker &> /dev/null; then
            DOCKER_CMD="docker"
          elif [ -f "/usr/bin/docker" ]; then
            DOCKER_CMD="/usr/bin/docker"
          elif [ -f "/usr/local/bin/docker" ]; then
            DOCKER_CMD="/usr/local/bin/docker"
          else
            echo "ERROR: Docker not found. Installing Docker..."
            # Install Docker if not found
            curl -fsSL https://get.docker.com -o get-docker.sh
            sh get-docker.sh
            rm get-docker.sh
            DOCKER_CMD="docker"
            # Add current user to docker group (may require logout/login)
            sudo usermod -aG docker $USER || true
          fi
          
          echo "Docker command: $DOCKER_CMD"
          $DOCKER_CMD --version
          
          # Use sudo if needed
          if ! $DOCKER_CMD ps &> /dev/null; then
            echo "Docker requires sudo, using sudo..."
            DOCKER_CMD="sudo $DOCKER_CMD"
          fi
          
          echo "=== Logging in to GitHub Container Registry ==="
          echo ${GITHUB_TOKEN} | $DOCKER_CMD login ghcr.io -u ${GITHUB_ACTOR} --password-stdin
          
          echo "=== Pulling latest image ==="
          $DOCKER_CMD pull ghcr.io/${IMAGE_NAME}:latest
          
          echo "=== Stopping and removing old container ==="
          $DOCKER_CMD stop app-container || true
          $DOCKER_CMD rm app-container || true
          
          echo "=== Starting new container ==="
          $DOCKER_CMD run -d --name app-container -p 8000:8000 \
            --restart unless-stopped \
            -e AWS_ACCESS_KEY_ID=${{ secrets.AWS_ACCESS_KEY_ID }} \
            -e AWS_SECRET_ACCESS_KEY=${{ secrets.AWS_SECRET_ACCESS_KEY }} \
            -e S3_BUCKET=${{ secrets.S3_BUCKET }} \
            ghcr.io/${IMAGE_NAME}:latest
          
          echo "=== Cleaning up old images ==="
          $DOCKER_CMD image prune -f
          
          echo "=== Container status ==="
          $DOCKER_CMD ps -a | grep app-container || true
