# MLOps Thá»±c HÃ nh

Má»™t dá»± Ã¡n MLOps hoÃ n chá»‰nh vá»›i YOLO model training, experiment tracking, vÃ  CI/CD pipeline tá»± Ä‘á»™ng.

## ğŸ“‹ MÃ´ táº£

Dá»± Ã¡n nÃ y triá»ƒn khai má»™t pipeline MLOps Ä‘áº§y Ä‘á»§ cho viá»‡c training vÃ  deploy YOLO model **phÃ¡t hiá»‡n Ä‘á»‘i tÆ°á»£ng (Object Detection)** trÃªn dataset COCO128 vá»›i 80 loáº¡i Ä‘á»‘i tÆ°á»£ng (ngÆ°á»i, xe cá»™, Ä‘á»™ng váº­t, Ä‘á»“ váº­t,...), bao gá»“m:

- **Model Training**: Training YOLO model vá»›i Ultralytics
- **Experiment Tracking**: Theo dÃµi experiments vá»›i MLflow
- **Model Registry**: Quáº£n lÃ½ vÃ  promote models vá»›i MLflow Model Registry
- **Data Versioning**: Quáº£n lÃ½ data vá»›i DVC (Data Version Control)
- **CI/CD Pipeline**: Tá»± Ä‘á»™ng train, build, vÃ  deploy vá»›i GitHub Actions
- **API Inference**: FastAPI service Ä‘á»ƒ serve model predictions

## ğŸ—ï¸ Kiáº¿n trÃºc

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  GitHub     â”‚
â”‚  (Trigger)  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  GitHub Actions CI/CD Pipeline       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚  â”‚ Job 1:   â”‚â†’ â”‚ Job 2:   â”‚         â”‚
â”‚  â”‚ Train    â”‚  â”‚ Build &  â”‚         â”‚
â”‚  â”‚ on EC2   â”‚  â”‚ Push     â”‚         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜         â”‚
â”‚                    â”‚                â”‚
â”‚                    â–¼                â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚              â”‚ Job 3:   â”‚           â”‚
â”‚              â”‚ Deploy   â”‚           â”‚
â”‚              â”‚ to EC2   â”‚           â”‚
â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                    â”‚
       â–¼                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  EC2 Server â”‚      â”‚  GHCR       â”‚
â”‚  (Training) â”‚      â”‚  (Registry) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  EC2 Server â”‚
â”‚  (Deploy)   â”‚
â”‚  FastAPI    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ TÃ­nh nÄƒng

### 1. Model Training
- Training YOLO models (YOLOv8, YOLOv11) vá»›i Ultralytics
- Tá»± Ä‘á»™ng evaluate trÃªn validation vÃ  test sets
- Model promotion logic dá»±a trÃªn mAP metrics

### 2. Experiment Tracking
- MLflow integration cho experiment tracking
- Log metrics, parameters, vÃ  artifacts
- Model versioning vÃ  registry

### 3. Data Versioning
- DVC Ä‘á»ƒ quáº£n lÃ½ datasets
- Tá»± Ä‘á»™ng detect data changes vÃ  trigger retraining
- S3 backend cho data storage

### 4. CI/CD Pipeline
- **Job 1 (train_on_server)**: SSH vÃ o EC2, pull code, train model
- **Job 2 (build_and_push)**: Build Docker image vÃ  push lÃªn GHCR
- **Job 3 (deploy_ec2)**: Deploy container lÃªn EC2 server

### 5. API Inference
- FastAPI service vá»›i `/predict` endpoint
- Health check endpoint
- Model loading tá»« S3 hoáº·c local

## ğŸ“¦ CÃ i Ä‘áº·t

### YÃªu cáº§u

- Python 3.11+
- Docker (cho deployment)
- AWS Account (cho S3 storage)
- EC2 instance (cho training vÃ  deployment)
- GitHub repository vá»›i Actions enabled

### Setup Local

1. **Clone repository**:
```bash
git clone https://github.com/your-username/mlops-thuc-hanh.git
cd mlops-thuc-hanh
```

2. **CÃ i Ä‘áº·t dependencies**:
```bash
pip install -r requirements.txt
```

3. **Setup DVC**:
```bash
dvc pull
```

4. **Cáº¥u hÃ¬nh environment variables**:
Táº¡o file `.env`:
```env
AWS_ACCESS_KEY_ID=your_access_key
AWS_SECRET_ACCESS_KEY=your_secret_key
S3_BUCKET=your_bucket_name
MLFLOW_TRACKING_URI=http://localhost:5001
```

5. **Start MLflow server** (optional, cho local tracking):
```bash
mlflow server --backend-store-uri sqlite:///./mlflow.db --serve-artifacts --host 0.0.0.0 --port 5001
```

## ğŸ¯ Sá»­ dá»¥ng

### Training Model

```bash
python train.py --epochs 100 --model yolo11n --batch 16
```

Hoáº·c sá»­ dá»¥ng DVC pipeline:
```bash
dvc repro
```

### Cháº¡y API Server

```bash
uvicorn app.main:app --host 0.0.0.0 --port 8000
```

### Test API

**Local:**
```bash
# Health check
curl http://localhost:8000/health

# Prediction
curl -X POST "http://localhost:8000/predict" \
  -H "Content-Type: multipart/form-data" \
  -F "file=@path/to/image.jpg"
```

**Production (EC2):**
```bash
# Health check
curl http://13.212.160.80:8000/health

# Root endpoint
curl http://13.212.160.80:8000/

# Prediction
curl -X POST "http://13.212.160.80:8000/predict" \
  -H "Content-Type: multipart/form-data" \
  -F "file=@path/to/image.jpg"
```

**LÆ°u Ã½:** Äáº£m báº£o Security Group cá»§a EC2 instance Ä‘Ã£ má»Ÿ port 8000 (TCP) cho inbound traffic.

## ğŸ”§ Cáº¥u hÃ¬nh

### DVC Configuration

File `dvc.yaml` Ä‘á»‹nh nghÄ©a training pipeline. Cáº¥u hÃ¬nh parameters trong `params.yaml`:

```yaml
train:
  epochs: 100
  model: yolo11n
  batch_size: 16
  imgsz: 640
```

### GitHub Actions Secrets

Cáº§n setup cÃ¡c secrets sau trong GitHub repository:

- `AWS_ACCESS_KEY_ID`: AWS access key
- `AWS_SECRET_ACCESS_KEY`: AWS secret key
- `S3_BUCKET`: S3 bucket name
- `EC2_HOST`: EC2 server IP/hostname
- `EC2_USER`: SSH username
- `EC2_KEY`: SSH private key
- `EC2_PORT_SSH`: SSH port (default: 22)
- `EC2_PORT_DEPLOY`: Deploy SSH port (default: 22)
- `GITHUB_TOKEN`: Auto-provided by GitHub Actions

## ğŸ“ Cáº¥u trÃºc Project

```
mlops-thuc-hanh/
â”œâ”€â”€ app/                    # FastAPI application
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ main.py            # API endpoints
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â”œâ”€â”€ deploy.yml     # CI/CD pipeline
â”‚       â””â”€â”€ test-ci.yml    # Test pipeline
â”œâ”€â”€ mlflow/                 # MLflow server config
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ docker-compose.yaml
â”œâ”€â”€ scripts/                # Utility scripts
â”‚   â”œâ”€â”€ hooks/
â”‚   â”œâ”€â”€ setup_dvc.sh
â”‚   â””â”€â”€ trigger_jenkins.py
â”œâ”€â”€ tests/                  # Unit tests
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ test_main.py
â”œâ”€â”€ data.dvc               # DVC data tracking
â”œâ”€â”€ dvc.yaml               # DVC pipeline definition
â”œâ”€â”€ params.yaml            # Training parameters
â”œâ”€â”€ train.py               # Training script
â”œâ”€â”€ Dockerfile             # Production Docker image
â”œâ”€â”€ requirements.txt       # Python dependencies
â”œâ”€â”€ pyproject.toml         # Project metadata
â””â”€â”€ README.md              # This file
```

## ğŸ§ª Testing

```bash
# Run tests
pytest tests/

# With coverage
pytest tests/ --cov=app --cov-report=html
```

## ğŸ“Š MLflow Dashboard

Sau khi start MLflow server, truy cáº­p:
```
http://localhost:5001
```

Xem experiments, metrics, vÃ  model registry.

## ğŸ”„ CI/CD Workflow

Workflow Ä‘Æ°á»£c trigger khi:
- `data/**` files thay Ä‘á»•i
- `data.dvc` file thay Ä‘á»•i
- Manual trigger via `workflow_dispatch`

Pipeline flow:
1. **Train**: SSH vÃ o EC2, train model vá»›i DVC
2. **Build**: Build Docker image vÃ  push lÃªn GHCR
3. **Deploy**: Deploy container lÃªn EC2

## ğŸ¤ ÄÃ³ng gÃ³p

Contributions are welcome! Please feel free to submit a Pull Request.

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ‘¤ Author

tandat88963820@gmail.com

## ğŸ™ Acknowledgments

- [Ultralytics](https://github.com/ultralytics/ultralytics) for YOLO models
- [MLflow](https://mlflow.org/) for experiment tracking
- [DVC](https://dvc.org/) for data versioning
- [FastAPI](https://fastapi.tiangolo.com/) for API framework
